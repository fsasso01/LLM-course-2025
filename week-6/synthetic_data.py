# from llama_index.llms.ollama import Ollama
# import dspy

# llm = Ollama(model="llama3", request_timeout=60.0)

# # you can use DSPY (https://github.com/stanfordnlp/dspy), but you can also choose another method of interacting with an LLM
# dspy.settings.configure(lm=llm)

# # Task: implement a method, that will take a query string as input and produce N misspelling variants of the query.
# # These variants with typos will be used to test a search engine quality.
# # Example
# # Query: machine learning applications
# # Possible Misspellings:
# # "machin learning applications" (missing "e" in "machine")
# # "mashine learning applications" (phonetically similar spelling of "machine")
# # "machine lerning aplications" (missing "a" in "learning" and "p" in "applications")
# # "machin lerning aplications" (combining multiple typos)
# # "mahcine learing aplication" (transposed letters in "machine" and typos in "learning" and "applications")
# #
# # Questions:
# # 1. Does the search engine produce the same results for all the variants?
# # 2. Do all variants make sense?
# # 3. How to improve robustness of the method, for example, skip known abbreviations, like JFK or NBC.
# # 4. Can you test multiple LLMs and figure out which one is the best?
# # 5. Do the misspellings capture a variety of error types (phonetic, omission, transposition, repetition)?

import csv
import os
import time
from llama_index.llms.groq import Groq

INPUT_FILE = 'web_search_queries.csv'
MISPELLINGS_PER_QUERY = 3

api_key = os.environ.get("GROQ_API_KEY") or ""
llm = Groq(model="llama-3.3-70b-versatile", api_key=api_key)

def generate_misspellings_with_llm(query, n=3):    
    prompt = (
        f"Generate {n} different misspelled variants of the search query: '{query}'.\n"
        f"Rules:\n"
        f"1. Simulate realistic human typing errors: phonetic (e.g. 'ph' -> 'f'), omissions, transpositions, repeated keys.\n"
        f"2. DO NOT modify well-known abbreviations like JFK, USA, NYC, IBM, HTML.\n"
        f"3. Output ONLY the {n} variants, one per line. No numbering, no introduction.\n"
        f"4. If the query is very short or impossible to misspell realistically, just repeat it."
    )
    
    try:
        response = llm.complete(prompt)
        variants = [line.strip() for line in response.text.split('\n') if line.strip()]
        return variants[:n]
    except Exception as e:
        print(f"Error with query '{query}': {e}")
        return []

def main():
    queries = []
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader, None)
            f.seek(0)
            if header: next(f) 
            
            for row in csv.reader(f):
                if row:
                    queries.append(row[-1])
    except FileNotFoundError:
        print(f"Error: {INPUT_FILE} not found.")
        return

    print(f"--- Start generating with LLM for {len(queries)} query ---")

    results = []
    for i, q in enumerate(queries):
        if i > 0 and i % 5 == 0: 
            print("Waiting...")
            time.sleep(3) 

        print(f"[{i+1}/{len(queries)}] Processing: '{q}'...")
        variants = generate_misspellings_with_llm(q, n=MISPELLINGS_PER_QUERY)
        results.append({'original': q, 'variants': variants})

    print("\n--- RESULTS GENERATED BY THE LLM ---")
    for item in results[:5]: 
        print(f"Original: {item['original']}")
        for v in item['variants']:
            print(f"  -> {v}")
        print("-" * 20)

if __name__ == "__main__":
    main()